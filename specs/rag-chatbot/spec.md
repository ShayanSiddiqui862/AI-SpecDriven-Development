# Feature Specification: Next.js/FastAPI RAG Chatbot using ChatKit SDKs

**Feature:** RAG Chatbot with Book Content Search
**Version:** 1.0
**Date:** 2025-12-13
**Author:** Claude Code

## Overview

Build a Retrieval-Augmented Generation (RAG) chatbot system that allows users to interact with book content through a Next.js frontend. The system uses FastAPI backend with OpenAI agents, Qdrant vector database, and ChatKit SDKs for seamless chat experience. The content is sourced from Markdown files in the `/docs` folder and processed using the `context7-Mcp` utility.

## Target Components
- **Frontend**: Next.js application with ChatKit.js integration
- **Backend**: FastAPI service with OpenAI Agent SDK
- **Vector Database**: Qdrant Cloud (Free Tier)
- **SDKs**: OpenAI Agent/ChatKit SDKs
- **Data Source**: Markdown files in `/docs` folder (book content)

---

## 1. Data Ingestion Pipeline (Python Script)

### 1.1 Content Processing
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **DIP.1** | **Content Processing** | The Markdown source files from `/docs` must be processed by the **`context7-Mcp`** utility to standardize chunking and metadata extraction *before* embedding. | Pre-processor: `context7-Mcp` |

### 1.2 Embedding Model
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **DIP.2** | **Embedding Model** | Use the sentence-transformers `all-MiniLM-L6-v2` model to generate embeddings for all chunks generated by **`context7-Mcp`**. | Vector Dimension: 384 (Note: all-MiniLM-L6-v2 produces 384-dim vectors, not 1536) |

### 1.3 Qdrant Indexing
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **DIP.3** | **Qdrant Indexing Method** | The final vectors and chunks must be uploaded to the Qdrant collection *exclusively* through the **`qdrant-mcp-server`** interface, not directly via `qdrant-client`. | Indexing Server: `qdrant-mcp-server` |

### 1.4 Qdrant Indexing Details
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **DIP.4** | **Qdrant Indexing Detail** | Create a persistent collection in Qdrant Cloud Free Tier. Ensure metadata includes the section/chapter information (as provided by `context7-Mcp`) for filtering flexibility. | Collection Name: `book_content`, Client: `qdrant-mcp-server` wrapper |

---

## 2. RAG Backend Service (FastAPI & OpenAI Agents/ChatKit)

### 2.1 Framework & SDK
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **RBS.1** | **Framework & SDK** | Build the backend API using FastAPI and the **OpenAI Agent SDK** for RAG orchestration. | Python 3.10+, FastAPI, `openai` Python SDK |

### 2.2 ChatKit Session Endpoint
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **RBS.2** | **ChatKit Session Endpoint** | Implement an endpoint to create a new ChatKit session, returning the `client_secret` to the Next.js frontend for secure communication. | `POST /api/chatkit/session` |

### 2.3 RAG Tool Implementation
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **RBS.3** | **RAG Tool Implementation** | Create a custom **Agent Tool** that handles retrieval from Qdrant vector database. The tool must interface with Qdrant through the qdrant-mcp-server to search for relevant book content based on user queries. | Agent System Prompt (Text) |

### 2.4 Contextual Query Support
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **RBS.4** | **Contextual Query Support** | The RAG system must accept an optional `selected_text` parameter from frontend queries and use it as additional context for the OpenAI agent's response generation. | Input Parameter: `selected_text` (optional) |

---

## 3. Next.js Frontend (Next.js & ChatKit.js)

### 3.1 Framework & Source
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.1** | **Framework & Source** | The frontend must be built using **Next.js**. The displayed content is the embedded Next.js documentation. | Next.js (App Router preferred) |

### 3.2 Book Content Display
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.2** | **Book Displaying** | The book must be displayed on frontend using /AI-book endpoint on frontend. | Endpoint: `/AI-book` |

### 3.3 Chat Interface
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.3** | **Chat Interface** | Embed the chat widget using the **ChatKit.js SDK**. | ChatKit React Component |

### 3.4 Text Selection Logic
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.4** | **Text Selection Logic** | Implement a global event listener to capture the text selected by the user specifically within the book content sections. | JavaScript `window.getSelection().toString()` |

### 3.5 Contextual Query Mechanism
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.5** | **Contextual Query Mechanism** | The frontend must send the selected text as a required auxiliary parameter (`selected_text`) in the payload to the Agent Tool when a question is submitted, enabling the **RBS.4** logic. | Input Payload structure: `{ message: string, selected_text: string \| null }` |

### 3.6 CORS Configuration
| Spec ID | Requirement | Detail | Key Metric/Tool |
| :--- | :--- | :--- | :--- |
| **FES.6** | **CORS Configuration** | Ensure the Next.js application can successfully make API calls to the deployed FastAPI service. | API Call Verification (Local & Production) |

---

## Acceptance Criteria

### Functional Requirements
- [ ] Markdown files from `/docs` are processed by `context7-Mcp` utility
- [ ] Content is chunked and embedded using `all-MiniLM-L6-v2` model
- [ ] Vectors are indexed in Qdrant Cloud via `qdrant-mcp-server`
- [ ] FastAPI backend serves RAG queries using OpenAI Agent SDK
- [ ] ChatKit session endpoint creates secure sessions
- [ ] Next.js frontend displays book content via `/AI-book` endpoint
- [ ] Text selection is captured when user selects content in book sections
- [ ] Selected text is sent as context to the RAG system
- [ ] CORS is properly configured between frontend and backend

### Non-Functional Requirements
- [ ] System supports up to 100 concurrent users with auto-scaling capability
- [ ] Response time under 2 seconds for typical queries
- [ ] Qdrant collection persists data between sessions
- [ ] Error handling with 3 retry attempts and 10s timeout for API calls
- [ ] Secure session management using OAuth 2.0 with JWT tokens
- [ ] Data retention: Indefinite storage with user consent management
- [ ] Fallback: Fail gracefully with user-friendly error message when Qdrant is unavailable

---

## Constraints & Assumptions

### Constraints
- Must use Qdrant Cloud Free Tier (storage limitations apply)
- Must use `context7-Mcp` for content preprocessing
- Must use `qdrant-mcp-server` for indexing operations
- Must use OpenAI Agent SDK for RAG orchestration
- Must use ChatKit SDKs for chat functionality

### Assumptions
- Markdown files in `/docs` are well-formatted
- OpenAI API keys and Qdrant credentials are available
- Network connectivity exists between all components
- User selections are limited to visible text content

---

## Clarifications

### Session 2025-12-13

- Q: How many concurrent users should the system support? → A: Target 100 concurrent users with auto-scaling capability
- Q: What authentication mechanism should be used for secure session management? → A: Implement OAuth 2.0 with JWT tokens for session management
- Q: How should error handling for network failures and timeouts be implemented? → A: Define API retry/timeout policies
- Q: What is the data retention policy for user sessions and chat history? → A: Retain data indefinitely with user consent management
- Q: What should happen when Qdrant vector database is unavailable? → A: Fail gracefully with user-friendly error message

## Out of Scope

- Real-time collaborative editing features
- Advanced document formatting beyond standard Markdown
- Integration with external content management systems
- Advanced analytics dashboard for usage metrics
- Multi-language support initially