# Data Model: Physical AI & Humanoid Robotics Textbook Content Structure

This data model describes the conceptual entities and their relationships within the Docusaurus-based textbook, managed entirely by the context7 MCP server. It focuses on the structure and organization of content rather than traditional database entities.

## Entities

### Textbook
- **Description**: The core deliverable; the complete Docusaurus site.
- **Fields**:
  - `title`: "Teaching Physical AI & Humanoid Robotics Course"
  - `version`: (e.g., v1.0)
  - `deployment_target`: GitHub Pages
  - `managed_by`: context7 MCP server
- **Relationships**:
  - Contains multiple Modules.
  - Contains additional sections (Course Details, Why Physical AI Matters, etc.).

### Module
- **Description**: A major section of the textbook, focusing on a specific technological area.
- **Fields**:
  - `name`: (e.g., "The Robotic Nervous System (ROS 2)")
  - `index`: Numerical order of the module (e.g., 1, 2, 3, 4)
  - `landing_page_path`: Path to the module's introduction page (e.g., `docs/module1/intro.md`)
- **Relationships**:
  - Belongs to the Textbook.
  - Contains multiple Chapters.

### Chapter
- **Description**: Sub-sections within modules, structured with learning objectives, theory, implementation, exercises, and references.
- **Fields**:
  - `title`: (e.g., "ROS 2 Humble Installation Guide")
  - `file_path`: Path to the chapter's markdown file (e.g., `docs/module1/ros2-install.md`)
  - `learning_objectives`: List of objectives
  - `content_sections`: Theory, Implementation, Exercises, References
- **Relationships**:
  - Belongs to a Module.
  - Contains Code Examples.

### Code Example
- **Description**: Working code snippets and complete ROS packages integrated into chapters.
- **Fields**:
  - `type`: (e.g., `snippet`, `ros_package`)
  - `language`: (e.g., `python`, `cpp`)
  - `location`: In-line within markdown or external file path (e.g., `code/module1/example.py`)
- **Relationships**:
  - Belongs to a Chapter.

### Humanoid Robot Model
- **Description**: URDF definitions for simulated and potentially physical robots.
- **Fields**:
  - `name`: (e.g., `ur5_robot`, `g1_humanoid`)
  - `urdf_path`: Path to the URDF file
  - `description`: Brief description of the robot model
- **Relationships**:
  - Referenced in Modules (e.g., Module 1 for URDF tutorials).

### Simulation Environment
- **Description**: Gazebo and Unity worlds with physics and interactive objects.
- **Fields**:
  - `platform`: (e.g., `Gazebo`, `Unity`, `Isaac Sim`)
  - `world_file_path`: Path to the simulation world definition file (e.g., `.world`, `.sdf`, `.usd`)
  - `interactive_objects`: List of interactive elements within the simulation
- **Relationships**:
  - Used in Modules (e.g., Module 2 for environment building).

### Sensor Data
- **Description**: Simulated and real-world data streams (LiDAR, RGB-D, IMU).
- **Fields**:
  - `type`: (e.g., `LiDAR`, `RGB-D Camera`, `IMU`)
  - `data_format`: (e.g., `point_cloud`, `image`, `imu_msg`)
  - `source`: (e.g., `simulation`, `realsense_d435i`)
- **Relationships**:
  - Generated by Simulation Environment.
  - Used for perception training in Modules.

### Voice Commands
- **Description**: Natural language input for robot control.
- **Fields**:
  - `command_text`: Raw voice input
  - `processed_text`: Transcribed text
  - `semantic_intent`: Task decomposition by LLM
- **Relationships**:
  - Input to VLA Module (Module 4).

### LLM Prompts
- **Description**: Engineered prompts for task decomposition by Large Language Models.
- **Fields**:
  - `template`: Prompt structure
  - `variables`: Dynamic inputs to the prompt
  - `output_format`: Expected output structure (e.g., ROS action sequence)
- **Relationships**:
  - Used in VLA Module (Module 4).

### Hardware Specifications
- **Description**: Details on workstations, Jetson kits, and robot options.
- **Fields**:
  - `category`: (e.g., `Workstation`, `Edge Device`, `Robot`)
  - `model`: (e.g., `RTX 3090`, `Jetson AGX Orin`, `Unitree Go2`)
  - `minimum_requirements`: (e.g., VRAM, CPU cores)
- **Relationships**:
  - Referenced in Course Details and Hardware Requirements sections.

### Docusaurus Site
- **Description**: The deployed web-based version of the textbook.
- **Fields**:
  - `base_url`: (e.g., `https://username.github.io/repo-name`)
  - `config_files`: (e.g., `docusaurus.config.js`, `sidebars.js`)
  - `navigation_elements`: Navbar, sidebar, breadcrumbs, search
- **Relationships**:
  - Generated from Textbook content.

### Instructor Resources
- **Description**: Supplementary materials for educators.
- **Fields**:
  - `type`: (e.g., `slide_template`, `assignment_sheet`, `solution_guide`)
  - `file_path`: Path to the resource file
- **Relationships**:
  - Separate section within the Textbook's content structure.

## Relationships and Data Flow

- The **Textbook** is composed of **Modules** and **Additional Sections**.
- Each **Module** contains multiple **Chapters**.
- Each **Chapter** can include **Code Examples**.
- **Humanoid Robot Models** and **Simulation Environments** are used within **Modules** and **Chapters**.
- **Sensor Data** is generated by **Simulation Environments** and used in **Modules**.
- **Voice Commands** are processed using **LLM Prompts** within the **VLA Module**.
- **Hardware Specifications** inform the requirements for running **Modules** and the **Capstone Project**.
- The **Docusaurus Site** is the rendered output of all content, configuration, and assets, managed by the context7 MCP server.
- **Instructor Resources** are a separate, but related, part of the overall textbook offering.
